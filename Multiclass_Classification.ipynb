{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tFLPTPp66FS"
      },
      "source": [
        "# Flowers classification with ```Iris dataset```\n",
        "\n",
        "Where regression was used to predict a numeric value, classification is used to seperate data points into classes of different labels.\n",
        "\n",
        "```We predict the probability of a flower to belong to that class.```\n",
        "\n",
        "we have :\n",
        "\n",
        "```Binary classification or Multiclass classification```\n",
        "\n",
        "and approaches are:\n",
        "```\n",
        "1. Logistic Regression (softmax function)\n",
        "2. LDA\n",
        "3. SVM\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GgGi_ku282K"
      },
      "source": [
        "# Setup and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dInQXyXk6bk-"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xLitQMe6sC7"
      },
      "source": [
        "# Data load and pre-process\n",
        "\n",
        "Iris dataset seperates flowers into 3 different classes of species.\n",
        "- Setosa\n",
        "- Versicolor\n",
        "- Virginica\n",
        "\n",
        "The information about each flower is the following.\n",
        "- sepal length\n",
        "- sepal width\n",
        "- petal length\n",
        "- petal width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1VtWUz69GR"
      },
      "source": [
        "features_col = ['SepalLength', 'SepalWidth', 'PetalLenght', 'PetalWidth', 'Species']\n",
        "species = ['Setosa', 'Versicolor','Virginica']\n",
        "\n",
        "# class 0 = 'Setosa'\n",
        "# class 1 = 'Versicolor'\n",
        "# class 2 = 'Virginica'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jtIL8e7nYf"
      },
      "source": [
        "# load dataset using Keras: use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe\n",
        "# tf.keras.utils.get_file(save_file, data_path_from_where_data_will_be_downloaded)\n",
        "\n",
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkpxtIdJ7nZl"
      },
      "source": [
        "train_data = pd.read_csv(train_path, names = features_col, header=0) # header 0 , means row 0 is the header\n",
        "test_data = pd.read_csv(test_path, names = features_col, header=0)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fX83ejMN7neD",
        "outputId": "5c949af8-3162-4a90-9373-501220903b2f"
      },
      "source": [
        "train_data.head()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLenght</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLenght  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA6LjwrvCFdX",
        "outputId": "5068c2e2-2087-4b16-829b-e6bda50db3d7"
      },
      "source": [
        "print(train_data.columns)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SepalLength', 'SepalWidth', 'PetalLenght', 'PetalWidth', 'Species'], dtype='object')\n",
            "(120, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB70Ljcl7ne8"
      },
      "source": [
        "# pop up last column to make it label for tarining\n",
        "\n",
        "y_train = train_data.pop('Species')\n",
        "y_test = test_data.pop('Species')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVgC9tcD7nkU",
        "outputId": "d63d2012-d42f-473c-9554-377230263f19"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120,)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGbsV0NO7no2",
        "outputId": "b6ffbabe-73fe-41d8-9129-7e8429f783b4"
      },
      "source": [
        "# now check train_data shape\n",
        "train_data.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq0np2UvC-hz"
      },
      "source": [
        "# Input function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyHp-xpXC-xt"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the Features/inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training: # if training= True\n",
        "        dataset = dataset.shuffle(1000).repeat() # shuffle and repeat 1000 times\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Jd_bAHlP7s"
      },
      "source": [
        "# Feature Columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy6fHTVAC-yq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccf6390-1f56-4d1b-caef-f2f7787f20fa"
      },
      "source": [
        "# Feature columns describe how to use the input/features from input function.\n",
        "\n",
        "feature_cols = []\n",
        "for key in train_data.keys(): # train_data.keys : gives all the dataset columns (after y_train removed)\n",
        "    feature_cols.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "print(feature_cols)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLenght', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXhq9bbNQNzV"
      },
      "source": [
        "# Create Model \n",
        "\n",
        "- can choose either DNN(Deep Neural Network) os LinearClassifier\n",
        "- DNN can give the best results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNhgdpIhC-3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "f144f205-4048-4638-d4e3-794953b6813e"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes(neurons) each.\n",
        "\n",
        "# tf.estimator: load bunch of pre-trained models and DNN Classifier is one of them\n",
        "\n",
        "dnn_classifier= tf.estimator.DNNClassifier(feature_columns = feature_cols,\n",
        "                                           # Two hidden layers of 30, 10 hidden nodes respectively (for 3 hidden layer use[30,10,10])\n",
        "                                           hidden_units = [30, 10],\n",
        "                                           # model has 3 classes\n",
        "                                           n_classes = 3)\n",
        "\n",
        "\n",
        "# note\n",
        "'''\n",
        "Hidden neurons/Nodes is an arbitrary number and many experiments and tests are usually done to determine the best choice for these values. \n",
        "Try playing around with the number of hidden neurons and see if your results change.\n",
        "'''"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwcfagan3\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwcfagan3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nHidden neurons/Nodes is an arbitrary number and many experiments and tests are usually done to determine the best choice for these values. \\nTry playing around with the number of hidden neurons and see if your results change.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qexur4STSeWN"
      },
      "source": [
        "## Train the Model on training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyF93lWC-4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f25186c-0523-44a4-ebd5-25bd483b3ec7"
      },
      "source": [
        "# passing values into input_fn(features = train_data, labels = y_train, training=True, batch_size=256):\n",
        "\n",
        "dnn_classifier.train(input_fn= lambda: input_fn(train_data, y_train, training=True), steps = 5000) # steps = epoch, batch_size did not pass here(mean it will take default value 256 from input_fn)\n",
        "\n",
        "# steps argument. This simply tells the classifier to run for 5000 steps. Try modifiying this and seeing if your results change. Keep in mind that more is not always better.\n",
        "# We include a lambda to avoid creating an inner function inside a function( in logistic regression we had to do that, check it)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwcfagan3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.2904072, step = 0\n",
            "INFO:tensorflow:global_step/sec: 351.061\n",
            "INFO:tensorflow:loss = 1.0142436, step = 100 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.19\n",
            "INFO:tensorflow:loss = 0.9705392, step = 200 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.32\n",
            "INFO:tensorflow:loss = 0.9183738, step = 300 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.456\n",
            "INFO:tensorflow:loss = 0.8834004, step = 400 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.727\n",
            "INFO:tensorflow:loss = 0.8600719, step = 500 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.87\n",
            "INFO:tensorflow:loss = 0.83669657, step = 600 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.537\n",
            "INFO:tensorflow:loss = 0.82148075, step = 700 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.731\n",
            "INFO:tensorflow:loss = 0.8018801, step = 800 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.799\n",
            "INFO:tensorflow:loss = 0.7787062, step = 900 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.209\n",
            "INFO:tensorflow:loss = 0.7581682, step = 1000 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.812\n",
            "INFO:tensorflow:loss = 0.73985195, step = 1100 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.57\n",
            "INFO:tensorflow:loss = 0.73712647, step = 1200 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.984\n",
            "INFO:tensorflow:loss = 0.7160297, step = 1300 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 425.682\n",
            "INFO:tensorflow:loss = 0.7048541, step = 1400 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 438.065\n",
            "INFO:tensorflow:loss = 0.6990793, step = 1500 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.156\n",
            "INFO:tensorflow:loss = 0.6914829, step = 1600 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.925\n",
            "INFO:tensorflow:loss = 0.66766226, step = 1700 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.195\n",
            "INFO:tensorflow:loss = 0.65214694, step = 1800 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.324\n",
            "INFO:tensorflow:loss = 0.64812607, step = 1900 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.833\n",
            "INFO:tensorflow:loss = 0.63374543, step = 2000 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.6\n",
            "INFO:tensorflow:loss = 0.63260144, step = 2100 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.322\n",
            "INFO:tensorflow:loss = 0.6292993, step = 2200 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.511\n",
            "INFO:tensorflow:loss = 0.6072577, step = 2300 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.134\n",
            "INFO:tensorflow:loss = 0.6086948, step = 2400 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.153\n",
            "INFO:tensorflow:loss = 0.59340346, step = 2500 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.896\n",
            "INFO:tensorflow:loss = 0.59270686, step = 2600 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.425\n",
            "INFO:tensorflow:loss = 0.5723423, step = 2700 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.179\n",
            "INFO:tensorflow:loss = 0.5719142, step = 2800 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.412\n",
            "INFO:tensorflow:loss = 0.56509227, step = 2900 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.753\n",
            "INFO:tensorflow:loss = 0.56008434, step = 3000 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.359\n",
            "INFO:tensorflow:loss = 0.54624736, step = 3100 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.574\n",
            "INFO:tensorflow:loss = 0.54904264, step = 3200 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.204\n",
            "INFO:tensorflow:loss = 0.53573644, step = 3300 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.816\n",
            "INFO:tensorflow:loss = 0.534333, step = 3400 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.554\n",
            "INFO:tensorflow:loss = 0.5274967, step = 3500 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 447.405\n",
            "INFO:tensorflow:loss = 0.5153675, step = 3600 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 426.536\n",
            "INFO:tensorflow:loss = 0.5287878, step = 3700 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.006\n",
            "INFO:tensorflow:loss = 0.49629492, step = 3800 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.018\n",
            "INFO:tensorflow:loss = 0.5017908, step = 3900 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 440.366\n",
            "INFO:tensorflow:loss = 0.5093274, step = 4000 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.316\n",
            "INFO:tensorflow:loss = 0.49193168, step = 4100 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.039\n",
            "INFO:tensorflow:loss = 0.4861761, step = 4200 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.018\n",
            "INFO:tensorflow:loss = 0.4817499, step = 4300 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 415.735\n",
            "INFO:tensorflow:loss = 0.47128713, step = 4400 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.318\n",
            "INFO:tensorflow:loss = 0.46613127, step = 4500 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.219\n",
            "INFO:tensorflow:loss = 0.4705823, step = 4600 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.608\n",
            "INFO:tensorflow:loss = 0.45070145, step = 4700 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.121\n",
            "INFO:tensorflow:loss = 0.46167374, step = 4800 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.577\n",
            "INFO:tensorflow:loss = 0.44868225, step = 4900 (0.229 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpwcfagan3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.44694012.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f29e05cbc90>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZevtmZhVQRA"
      },
      "source": [
        "# Model Evaluation on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTy7IzLUC-9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf8e439-fbef-4b1a-bb8d-5772596ba629"
      },
      "source": [
        "evaluation = dnn_classifier.evaluate(input_fn= lambda: input_fn(test_data, y_test, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**evaluation))\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-19T19:36:24\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpwcfagan3/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.26635s\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-19-19:36:24\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.5162411, global_step = 5000, loss = 0.5162411\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpwcfagan3/model.ckpt-5000\n",
            "\n",
            "Test set accuracy: 0.933\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIgmWPzLWLBB"
      },
      "source": [
        "# Prediciton for new dataset\n",
        "\n",
        "- user will end features value, and model will predict which class it belongs to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBywcjYcC-_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "b8a3243c-ab2b-4ee8-f187-5674323cd326"
      },
      "source": [
        "# creating a input function to convert Features into Dataset\n",
        "# convert features.inputs to a dataset without labels\n",
        "\n",
        "def input_func(features, batch_size=256): # remeber we are not giving label here because while predicitng value, we dont have label--> we want the label (that is our task)\n",
        "        return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size) ## it will return a dict\n",
        "\n",
        "# defining all the featurs into a list\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "\n",
        "### going to take input from user as a list (becase feature value are stores as a list) and convert it into a dict for input_func\n",
        "predict= {}\n",
        "print('Please type numeric value as promped: ')\n",
        "# the coming code to take input from user and validate it if it's in a right type \n",
        "for i in features:\n",
        "  valid = True\n",
        "  while valid:\n",
        "    value = input(i + \": \")\n",
        "    if not value.isdigit(): valid = False ## if entered user input is not digit, validation fails\n",
        "\n",
        "  predict[i] = [float(value)] ## predict[i] --i = key and [float] --> a list because feature_col is a list and expect all value inside a list \n",
        "\n",
        "\n",
        "prediciton = dnn_classifier.predict(input_func=lambda:input_func(predict))  \n",
        "for pred_dict in prediciton:\n",
        "  class_id = pred_dict['class_ids'][0]\n",
        "  prob = pred_dict['probabilities'][class_id]\n",
        "\n",
        "  print('Prediction is \"{}\"  (:.1f%)'.format(species[class_id], 100*prob))\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please type numeric value as promped: \n",
            "SepalLength: 2.3\n",
            "SepalWidth: 3.3\n",
            "PetalLength: 4.4\n",
            "PetalWidth: 5.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-13b1713ae88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprediciton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediciton\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'input_func'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h9TmpX7C_Dv"
      },
      "source": [
        "# some example input and expected classes you can try above\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "predict_x = {\n",
        "    'SepalLength': [5.1, 5.9, 6.9],\n",
        "    'SepalWidth': [3.3, 3.0, 3.1],\n",
        "    'PetalLength': [1.7, 4.2, 5.4],\n",
        "    'PetalWidth': [0.5, 1.5, 2.1],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH7rjLRLC_Ie"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpq1q0AcC_JW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw7EkXQZC_OB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhPzlBlXC_O7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWGtzUvQ7npz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}